{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b0f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0705c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IMAGES\n",
    "imgs_left = glob.glob(r'.\\Stereo_calibration_images\\left*.png')\n",
    "imgs_right = glob.glob(r'.\\Stereo_calibration_images\\right*.png')\n",
    "\n",
    "assert imgs_right, imgs_left\n",
    "assert (len(imgs_right) == len(imgs_left))\n",
    "n_images = len(imgs_right)\n",
    "imgs_right.sort()\n",
    "imgs_left.sort()\n",
    "\n",
    "# %% INITIALIZE CHECKERBOARD OBJECT POINTS\n",
    "nb_vertical = 9\n",
    "nb_horizontal = 6\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nb_horizontal*nb_vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nb_vertical,0:nb_horizontal].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # vector of vectors of calibration pattern points in the calibration pattern coordinate space\n",
    "imgpoints_left = [] # 2d points in image plane.\n",
    "imgpoints_right = [] # 2d points in image plane.\n",
    "\n",
    "# %% EXTRACT CHECKERBOARD CORNERS (AND DISPLAY THEM)\n",
    "for i in range(n_images):\n",
    "    img_left = cv2.imread(imgs_left[i])\n",
    "    img_right = cv2.imread(imgs_right[i])\n",
    "    gray_left = cv2.cvtColor(img_left,cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(img_right,cv2.COLOR_BGR2GRAY)\n",
    "    ret_left, corners_left = cv2.findChessboardCorners(gray_left, patternSize = (nb_vertical, nb_horizontal))\n",
    "    ret_right, corners_right = cv2.findChessboardCorners(gray_right, patternSize = (nb_vertical, nb_horizontal))\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret_left == True and ret_right == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints_left.append(corners_left)\n",
    "        imgpoints_right.append(corners_right)\n",
    "        # Draw and display the corners\n",
    "        img_left = cv2.drawChessboardCorners(img_left, (nb_vertical,nb_horizontal), corners_left,ret_left)\n",
    "        img_right = cv2.drawChessboardCorners(img_right, (nb_vertical,nb_horizontal), corners_right,ret_right)\n",
    "        cv2.putText(img_left, \"Left Camera\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(img_right, \"Right Camera\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        img_l_r = np.vstack((img_left,img_right))\n",
    "        windowname_1 = \"Calibration Pattern (Left and Right Camera)\"\n",
    "        cv2.namedWindow(windowname_1, cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(windowname_1, 600, 600)\n",
    "        cv2.imshow(windowname_1,img_l_r)\n",
    "        cv2.waitKey(5)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# %% STEREOCALIBRATE - COMPUTE (INTRINSIC) CAMERA MATRICES, DISTORTION COEFFICIENTS, ROTATION AND TRANSLATION BETWEEN THE TWO CAMERAS AND REPROJECTION ERROR\n",
    "assert (img_left.shape[:2] == img_right.shape[:2])\n",
    "h, w = img_left.shape[:2]\n",
    "\n",
    "term_crit_sc = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "flags_sc = cv2.CALIB_RATIONAL_MODEL\n",
    "ret_stereo,  mtx_left, dist_left, mtx_right, dist_right, mtx_R, mtx_T, mtx_E, mtx_F = cv2.stereoCalibrate(objpoints, imgpoints_left, imgpoints_right, None, None, None, None, (w,h), flags=flags_sc, criteria=term_crit_sc)\n",
    "\n",
    "\n",
    "# %% STEREORECTIFY - COMPUTE AND SAVE THE RECTIFICATION TRANSFORM AND PROJECTION MATRIX OF THE 2 CAMERAS, USING THE MATRICES COMPUTED BY STEREOCALIBRATE\n",
    "\n",
    "mtx_R_left, mtx_R_right, mtx_P_left, mtx_P_right, mtx_Q, roi_rec_left, roi_rec_right = cv2.stereoRectify(mtx_left, dist_left, mtx_right, dist_right, (w,h), mtx_R, mtx_T, alpha=0)\n",
    "\n",
    "# %% COMPUTE UNDISTORTION AND RECTIFICATION TRANSFORMATION MAP\n",
    "map1x, map1y = cv2.initUndistortRectifyMap(mtx_left,dist_left,mtx_R_left,mtx_P_left,(w,h),cv2.CV_32FC1)\n",
    "map2x, map2y = cv2.initUndistortRectifyMap(mtx_right,dist_right,mtx_R_right,mtx_P_right,(w,h),cv2.CV_32FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fa6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% SAVE RECTIFIED CAMERA MATRICES AND UNDISTORTION/RECTIFICATION MAPS FOR FUTURE USE\n",
    "#dir_calib = (r\"C:\\Users\\K_kar\\Downloads\\Stereo_calibration_images\\matrix_calib_rectify\")\n",
    "#np.save(dir_calib + \"\\projection_matrix_left\", mtx_P_left)\n",
    "#np.save(dir_calib + \"\\projection_matrix_right\", mtx_P_right)\n",
    "#np.save(dir_calib + \"\\map_left_x\", map1x)\n",
    "#np.save(dir_calib + \"\\map_left_y\", map1y)\n",
    "#np.save(dir_calib + \"\\map_right_x\", map2x)\n",
    "#np.save(dir_calib + \"\\map_right_y\", map2y)\n",
    "\n",
    "# %% CHECK RESULT CORRECTNESS\n",
    "\n",
    "img_left = cv2.imread(imgs_left[0])\n",
    "cv2.imshow('Distorted Image', img_left)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_left_undist_rect = cv2.remap(img_left, map1x, map1y, cv2.INTER_LINEAR)\n",
    "cv2.imshow('Undistorted and Rectified Image', img_left_undist_rect)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1bda237",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\K_kar\\\\Downloads\\\\Stereo_calibration_images\\\\matrix_calib_rectify\\\\map_left_x.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m img1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mK_kar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPictures\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m31392 Perception for Autonomous Systems\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStereo_conveyor_without_occlusions\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1585434279_805531979_Left.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mK_kar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPictures\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m31392 Perception for Autonomous Systems\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinal Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStereo_conveyor_without_occlusions\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1585434279_805531979_right.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m rect_map_left_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mK_kar\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mStereo_calibration_images\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmatrix_calib_rectify\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmap_left_x.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m rect_map_left_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mK_kar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStereo_calibration_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmatrix_calib_rectify\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmap_left_y.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m rect_map_right_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mK_kar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStereo_calibration_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmatrix_calib_rectify\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmap_right_x.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\site-packages\\numpy\\lib\\npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    418\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\K_kar\\\\Downloads\\\\Stereo_calibration_images\\\\matrix_calib_rectify\\\\map_left_x.npy'"
     ]
    }
   ],
   "source": [
    "#map the matrix file with images\n",
    "img1 = cv2.imread(r'.\\Stereo_conveyor_without_occlusions\\left\\1585434279_805531979_Left.png', 0)\n",
    "img2 = cv2.imread(r'.\\Stereo_conveyor_without_occlusions\\right\\1585434279_805531979_right.png', 0)\n",
    "rect_map_left_x = np.load(r'C:\\Users\\K_kar\\Downloads\\Stereo_calibration_images\\matrix_calib_rectify\\map_left_x.npy')\n",
    "rect_map_left_y = np.load(r'C:\\Users\\K_kar\\Downloads\\Stereo_calibration_images\\matrix_calib_rectify\\map_left_y.npy')\n",
    "rect_map_right_x = np.load(r'C:\\Users\\K_kar\\Downloads\\Stereo_calibration_images\\matrix_calib_rectify\\map_right_x.npy')\n",
    "rect_map_right_y = np.load(r'C:\\Users\\K_kar\\Downloads\\Stereo_calibration_images\\matrix_calib_rectify\\map_right_y.npy')\n",
    "img1 = cv2.remap(img1, rect_map_left_x, rect_map_left_y, cv2.INTER_LINEAR)\n",
    "img2 = cv2.remap(img2, rect_map_right_x, rect_map_right_y, cv2.INTER_LINEAR)\n",
    "print(img1_size)\n",
    "#Detect keypoints here\n",
    "sift = cv2.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "kp_img = cv2.drawKeypoints(img2, kp2, img2, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(kp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612a7d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'des1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15428/37348665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# FLANN parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mflann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlannBasedMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdes2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'des1' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement Flann Based matcher here\n",
    "matches = ...\n",
    "\"\"\"\n",
    "\n",
    "# FLANN parameters\n",
    "flann = cv2.FlannBasedMatcher()\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "matches = [m for m, n in matches]\n",
    "\n",
    "# Sort them in the order of their distance (i.e. best matches first).\n",
    "matches = sorted(matches, key = lambda x:x.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7bd9fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15428/2875646277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpts2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnb_matches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mgood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpts1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueryIdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "nb_matches = 200\n",
    "\n",
    "good = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "for m in matches[:nb_matches]:\n",
    "    good.append(m)\n",
    "    pts1.append(kp1[m.queryIdx].pt)\n",
    "    pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "    \n",
    "\n",
    "#Implement findFundamentalMat here:\n",
    "F, mask = cv2.findFundamentalMat(pts1, pts2)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel() == 1]\n",
    "pts2 = pts2[mask.ravel() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b190b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c = img1.shape\n",
    "    img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,2)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e27b261",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15428/3063166779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Find epilines corresponding to points in right image (second image) and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# drawing its lines on left image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlines1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeCorrespondEpilines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlines1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlines1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrawlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2 ,F)\n",
    "lines1 = lines1.reshape(-1, 3)\n",
    "img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "lines2 = lines2.reshape(-1, 3)\n",
    "img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(10,10))\n",
    "axs[0, 0].imshow(img4)\n",
    "axs[0, 0].set_title('left keypoints')\n",
    "axs[0, 1].imshow(img6)\n",
    "axs[0, 1].set_title('right keypoints')\n",
    "axs[1, 0].imshow(img5)\n",
    "axs[1, 0].set_title('left epipolar lines')\n",
    "axs[1, 1].imshow(img3)\n",
    "axs[1, 1].set_title('right epipolar lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858a327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
